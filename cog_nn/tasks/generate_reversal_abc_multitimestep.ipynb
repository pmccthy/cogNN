{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Generate Reversal ABC Multi-Timestep Task Sequence**\n",
        "\n",
        "This notebook generates reversal ABC task sequences with multi-timestep trial structure:\n",
        "\n",
        "**Trial Structure:**\n",
        "- **Stimulus window**: Multiple timesteps showing the stimulus\n",
        "- **Reward availability window**: Multiple timesteps where reward can be obtained\n",
        "- **Outcome state**: Single timestep showing outcome (determined by action)\n",
        "- **ITI**: Random timesteps (between min_iti and max_iti) showing no stimulus\n",
        "\n",
        "**Task Rules:**\n",
        "- Stimulus A: Always rewarded in pre-reversal, never in post-reversal\n",
        "- Stimulus B: Never rewarded in pre-reversal, 50% rewarded in post-reversal\n",
        "- Stimulus C: Random reward (50% probability, doesn't reverse)\n",
        "\n",
        "Sequences are saved as pickle files for use with Gymnasium environments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Define Stimuli and Rewards\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define stimulus identities and reward values\n",
        "stimuli = {\"A\": 0, \"B\": 1, \"C\": 2}\n",
        "rewards = {\"no_reward\": 0, \"reward\": 1}\n",
        "\n",
        "def generate_random_reward(reward1, reward2, prob):\n",
        "    \"\"\"Generate random reward with given probability.\"\"\"\n",
        "    if np.random.rand(1) < prob:\n",
        "        return reward1\n",
        "    else:\n",
        "        return reward2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Set Task Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Task parameters\n",
        "num_pre_reversal_trials = 4000  # Number of trials before reversal\n",
        "num_post_reversal_trials = 4000  # Number of trials after reversal\n",
        "\n",
        "# Trial structure parameters\n",
        "stim_window = 5      # Number of timesteps for stimulus presentation\n",
        "reward_window = 3    # Number of timesteps for reward availability\n",
        "min_iti = 10         # Minimum ITI timesteps\n",
        "max_iti = 20         # Maximum ITI timesteps\n",
        "\n",
        "# Random seed\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "print(f\"Task parameters:\")\n",
        "print(f\"  Pre-reversal trials: {num_pre_reversal_trials}\")\n",
        "print(f\"  Post-reversal trials: {num_post_reversal_trials}\")\n",
        "print(f\"  Stimulus window: {stim_window} timesteps\")\n",
        "print(f\"  Reward window: {reward_window} timesteps\")\n",
        "print(f\"  ITI range: {min_iti}-{max_iti} timesteps\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Generate Trial-Level Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate trial-level data (stimulus and reward availability)\n",
        "trial_data = {\n",
        "    \"stimuli\": [],\n",
        "    \"rewards\": [],\n",
        "    \"masks\": {\"reversal\": []}\n",
        "}\n",
        "\n",
        "# Pre-reversal phase: A rewarded, B not, C random 50%\n",
        "for _ in range(num_pre_reversal_trials):\n",
        "    stim = np.random.choice([stimuli[\"A\"], stimuli[\"B\"], stimuli[\"C\"]], p=[1/3, 1/3, 1/3])\n",
        "    \n",
        "    if stim == stimuli[\"A\"]:\n",
        "        reward = rewards[\"reward\"]\n",
        "    elif stim == stimuli[\"B\"]:\n",
        "        reward = rewards[\"no_reward\"]\n",
        "    else:  # C\n",
        "        reward = generate_random_reward(rewards[\"reward\"], rewards[\"no_reward\"], prob=0.5)\n",
        "    \n",
        "    trial_data[\"stimuli\"].append(stim)\n",
        "    trial_data[\"rewards\"].append(reward)\n",
        "    trial_data[\"masks\"][\"reversal\"].append(0)\n",
        "\n",
        "# Post-reversal phase: A not rewarded, B rewarded, C still random 50%\n",
        "for _ in range(num_post_reversal_trials):\n",
        "    stim = np.random.choice([stimuli[\"A\"], stimuli[\"B\"], stimuli[\"C\"]], p=[1/3, 1/3, 1/3])\n",
        "    \n",
        "    if stim == stimuli[\"A\"]:\n",
        "        reward = rewards[\"no_reward\"]\n",
        "    elif stim == stimuli[\"B\"]:\n",
        "        reward = rewards[\"reward\"]\n",
        "    else:  # C\n",
        "        reward = generate_random_reward(rewards[\"reward\"], rewards[\"no_reward\"], prob=0.5)\n",
        "    \n",
        "    trial_data[\"stimuli\"].append(stim)\n",
        "    trial_data[\"rewards\"].append(reward)\n",
        "    trial_data[\"masks\"][\"reversal\"].append(1)\n",
        "\n",
        "print(f\"Generated trial-level data:\")\n",
        "print(f\"  Total trials: {len(trial_data['stimuli'])}\")\n",
        "print(f\"  Pre-reversal: {num_pre_reversal_trials} trials\")\n",
        "print(f\"  Post-reversal: {num_post_reversal_trials} trials\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Expand to Timestep-Level Sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now expand to timestep-level sequence\n",
        "# States: A=0, B=1, C=2, reward_unknown=3, unrewarded=4, rewarded=5, ITI=6\n",
        "state_map = {\"A\": 0, \"B\": 1, \"C\": 2, \"reward_unknown\": 3, \"unrewarded\": 4, \"rewarded\": 5, \"ITI\": 6}\n",
        "state_sequence = []\n",
        "reward_sequence = []\n",
        "trial_structure = []  # Track which timesteps belong to which trial and phase\n",
        "\n",
        "trial_idx = 0\n",
        "timestep = 0\n",
        "\n",
        "for stim, reward_avail, reversal_phase in zip(\n",
        "    trial_data[\"stimuli\"],\n",
        "    trial_data[\"rewards\"],\n",
        "    trial_data[\"masks\"][\"reversal\"]\n",
        "):\n",
        "    trial_start_timestep = timestep\n",
        "    \n",
        "    # Stimulus window: show stimulus\n",
        "    stim_timesteps = []\n",
        "    for _ in range(stim_window):\n",
        "        state_sequence.append(stim)  # Stimulus state\n",
        "        reward_sequence.append(0.0)  # No reward during stimulus window\n",
        "        stim_timesteps.append(timestep)\n",
        "        timestep += 1\n",
        "    \n",
        "    # Reward availability window: start in \"reward_unknown\" outcome state\n",
        "    # The environment will transition to rewarded/unrewarded based on action\n",
        "    reward_timesteps = []\n",
        "    for _ in range(reward_window):\n",
        "        state_sequence.append(state_map[\"reward_unknown\"])  # Outcome state, reward unknown\n",
        "        reward_sequence.append(1.0 if reward_avail == rewards[\"reward\"] else 0.0)\n",
        "        reward_timesteps.append(timestep)\n",
        "        timestep += 1\n",
        "    \n",
        "    # No separate outcome_timestep - outcome is determined during reward window\n",
        "    \n",
        "    # ITI: random length\n",
        "    iti_length = np.random.randint(min_iti, max_iti + 1)\n",
        "    iti_timesteps = []\n",
        "    for _ in range(iti_length):\n",
        "        state_sequence.append(state_map[\"ITI\"])\n",
        "        reward_sequence.append(0.0)\n",
        "        iti_timesteps.append(timestep)\n",
        "        timestep += 1\n",
        "    \n",
        "    trial_structure.append({\n",
        "        \"trial_idx\": trial_idx,\n",
        "        \"stimulus\": stim,\n",
        "        \"reward_available\": reward_avail == rewards[\"reward\"],\n",
        "        \"reversal_phase\": reversal_phase,\n",
        "        \"trial_start\": trial_start_timestep,\n",
        "        \"stim_window\": stim_timesteps,\n",
        "        \"reward_window\": reward_timesteps,  # These are the \"reward_unknown\" outcome states\n",
        "        \"iti_window\": iti_timesteps,\n",
        "        \"trial_end\": timestep - 1\n",
        "    })\n",
        "    \n",
        "    trial_idx += 1\n",
        "\n",
        "print(f\"Expanded to timestep-level sequence:\")\n",
        "print(f\"  Total timesteps: {len(state_sequence)}\")\n",
        "print(f\"  Average trial length: {len(state_sequence) / len(trial_structure):.1f} timesteps\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Convert to One-Hot Encoding (7D)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to one-hot encoding\n",
        "# States: A=0, B=1, C=2, reward_unknown=3, unrewarded=4, rewarded=5, ITI=6\n",
        "# We'll use 7D encoding: [A, B, C, reward_unknown, unrewarded, rewarded, ITI]\n",
        "state_sequence_ohe_7d = np.zeros((len(state_sequence), 7), dtype=np.float32)\n",
        "for i, state_idx in enumerate(state_sequence):\n",
        "    if 0 <= state_idx < 7:\n",
        "        state_sequence_ohe_7d[i, state_idx] = 1.0\n",
        "    # ITI (6) is encoded as [0, 0, 0, 0, 0, 0, 1]\n",
        "\n",
        "print(f\"Converted to one-hot encoding:\")\n",
        "print(f\"  State sequence shape: {state_sequence_ohe_7d.shape}\")\n",
        "print(f\"  Reward sequence shape: {len(reward_sequence)}\")\n",
        "print(f\"  Number of trials: {len(trial_structure)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Calculate Phase Boundaries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate phase boundaries\n",
        "pre_reversal_end_timestep = trial_structure[num_pre_reversal_trials - 1][\"trial_end\"] + 1\n",
        "phase_boundaries = {\n",
        "    \"reversal_points\": [pre_reversal_end_timestep],\n",
        "    \"pre_reversal\": {\n",
        "        \"start\": 0,\n",
        "        \"end\": pre_reversal_end_timestep\n",
        "    },\n",
        "    \"post_reversal\": {\n",
        "        \"start\": pre_reversal_end_timestep,\n",
        "        \"end\": timestep\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"Phase boundaries:\")\n",
        "print(f\"  Pre-reversal: timesteps {phase_boundaries['pre_reversal']['start']} to {phase_boundaries['pre_reversal']['end']}\")\n",
        "print(f\"  Post-reversal: timesteps {phase_boundaries['post_reversal']['start']} to {phase_boundaries['post_reversal']['end']}\")\n",
        "print(f\"  Reversal point: {phase_boundaries['reversal_points']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Prepare Data Dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data dictionary\n",
        "data = {\n",
        "    \"state_sequence_ohe\": state_sequence_ohe_7d,\n",
        "    \"reward_sequence\": np.array(reward_sequence, dtype=np.float32),\n",
        "    \"sequence\": {\n",
        "        \"stimuli\": trial_data[\"stimuli\"],\n",
        "        \"rewards\": trial_data[\"rewards\"],\n",
        "        \"masks\": trial_data[\"masks\"]\n",
        "    },\n",
        "    \"phase_boundaries\": phase_boundaries,\n",
        "    \"trial_structure\": trial_structure,\n",
        "    \"state_map\": {\"A\": 0, \"B\": 1, \"C\": 2, \"reward_unknown\": 3, \"unrewarded\": 4, \"rewarded\": 5, \"ITI\": 6},\n",
        "    \"trial_params\": {\n",
        "        \"stim_window\": stim_window,\n",
        "        \"reward_window\": reward_window,\n",
        "        \"min_iti\": min_iti,\n",
        "        \"max_iti\": max_iti\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Data dictionary prepared:\")\n",
        "print(f\"  Keys: {list(data.keys())}\")\n",
        "print(f\"  State sequence shape: {data['state_sequence_ohe'].shape}\")\n",
        "print(f\"  Reward sequence length: {len(data['reward_sequence'])}\")\n",
        "print(f\"  Trial structure length: {len(data['trial_structure'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Save Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save to pickle file\n",
        "output_path = Path(\"/Users/pmccarthy/Documents/cogNN/task_data/reversal_abc_multitimestep.pkl\")\n",
        "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(output_path, \"wb\") as f:\n",
        "    pickle.dump(data, f)\n",
        "\n",
        "print(f\"\\nGenerated reversal_abc_multitimestep task:\")\n",
        "print(f\"  Total timesteps: {len(data['state_sequence_ohe'])}\")\n",
        "print(f\"  Pre-reversal: {phase_boundaries['pre_reversal']['end']} timesteps\")\n",
        "print(f\"  Post-reversal: {phase_boundaries['post_reversal']['end'] - phase_boundaries['post_reversal']['start']} timesteps\")\n",
        "print(f\"  Saved to: {output_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
