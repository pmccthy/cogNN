{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Task Sequence Generation**\n",
    "\n",
    "This notebook generates reversal learning task sequences:\n",
    "- **reversal_ab**: Two-stimulus reversal learning task\n",
    "- **reversal_abc**: Three-stimulus reversal learning task (Sandra's task) with C having random 50% reward\n",
    "\n",
    "Sequences are saved as pickle files for use with Gymnasium environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Define Stimuli and Rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stimulus identities and reward values\n",
    "stimuli = {\"A\": 0, \"B\": 1, \"C\": 2}\n",
    "rewards = {\"no_reward\": 0, \"reward\": 1}\n",
    "\n",
    "def generate_random_reward(reward1, reward2, prob):\n",
    "    \"\"\"Generate random reward with given probability.\"\"\"\n",
    "    if np.random.rand(1) < prob:\n",
    "        return reward1\n",
    "    else:\n",
    "        return reward2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Generate Reversal AB Task Sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated reversal_ab sequence: 200 timesteps\n",
      "  Pre-reversal: 100 trials\n",
      "  Post-reversal: 100 trials\n"
     ]
    }
   ],
   "source": [
    "# Parameters for reversal AB task\n",
    "num_pre_reversal_trials = 100  # A rewarded, B not\n",
    "num_post_reversal_trials = 100  # A not rewarded, B rewarded\n",
    "\n",
    "reversal_ab = {\n",
    "    \"stimuli\": [],\n",
    "    \"rewards\": [],\n",
    "    \"masks\": {\"reversal\": []}\n",
    "}\n",
    "\n",
    "# Pre-reversal phase: A rewarded, B not\n",
    "for _ in range(num_pre_reversal_trials):\n",
    "    stim = np.random.choice([stimuli[\"A\"], stimuli[\"B\"]], p=[0.5, 0.5])\n",
    "    if stim == stimuli[\"A\"]:\n",
    "        reward = rewards[\"reward\"]\n",
    "    else:\n",
    "        reward = rewards[\"no_reward\"]\n",
    "    \n",
    "    reversal_ab[\"stimuli\"].append(stim)\n",
    "    reversal_ab[\"rewards\"].append(reward)\n",
    "    reversal_ab[\"masks\"][\"reversal\"].append(0)\n",
    "\n",
    "# Post-reversal phase: A not rewarded, B rewarded\n",
    "for _ in range(num_post_reversal_trials):\n",
    "    stim = np.random.choice([stimuli[\"A\"], stimuli[\"B\"]], p=[0.5, 0.5])\n",
    "    if stim == stimuli[\"A\"]:\n",
    "        reward = rewards[\"no_reward\"]\n",
    "    else:\n",
    "        reward = rewards[\"reward\"]\n",
    "    \n",
    "    reversal_ab[\"stimuli\"].append(stim)\n",
    "    reversal_ab[\"rewards\"].append(reward)\n",
    "    reversal_ab[\"masks\"][\"reversal\"].append(1)\n",
    "\n",
    "print(f\"Generated reversal_ab sequence: {len(reversal_ab['stimuli'])} timesteps\")\n",
    "print(f\"  Pre-reversal: {num_pre_reversal_trials} trials\")\n",
    "print(f\"  Post-reversal: {num_post_reversal_trials} trials\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Generate Reversal ABC Task Sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated reversal_abc sequence: 8000 timesteps\n",
      "  Pre-reversal: 4000 trials\n",
      "  Post-reversal: 4000 trials\n"
     ]
    }
   ],
   "source": [
    "# Parameters for reversal ABC task\n",
    "num_expected_occurrences = 4000  # Before reversal\n",
    "num_unexpected_occurrences = 4000  # After reversal\n",
    "\n",
    "reversal_abc = {\n",
    "    \"stimuli\": [],\n",
    "    \"rewards\": [],\n",
    "    \"masks\": {\"reversal\": []}\n",
    "}\n",
    "\n",
    "# Pre-reversal phase: A rewarded, B not, C random 50%\n",
    "for _ in range(num_expected_occurrences):\n",
    "    stim = np.random.choice([stimuli[\"A\"], stimuli[\"B\"], stimuli[\"C\"]], p=[1/3, 1/3, 1/3])\n",
    "    \n",
    "    if stim == stimuli[\"A\"]:\n",
    "        reward = rewards[\"reward\"]\n",
    "    elif stim == stimuli[\"B\"]:\n",
    "        reward = rewards[\"no_reward\"]\n",
    "    else:  # C\n",
    "        reward = generate_random_reward(rewards[\"reward\"], rewards[\"no_reward\"], prob=0.5)\n",
    "    \n",
    "    reversal_abc[\"stimuli\"].append(stim)\n",
    "    reversal_abc[\"rewards\"].append(reward)\n",
    "    reversal_abc[\"masks\"][\"reversal\"].append(0)\n",
    "\n",
    "# Post-reversal phase: A not rewarded, B rewarded, C still random 50%\n",
    "for _ in range(num_unexpected_occurrences):\n",
    "    stim = np.random.choice([stimuli[\"A\"], stimuli[\"B\"], stimuli[\"C\"]], p=[1/3, 1/3, 1/3])\n",
    "    \n",
    "    if stim == stimuli[\"A\"]:\n",
    "        reward = rewards[\"no_reward\"]\n",
    "    elif stim == stimuli[\"B\"]:\n",
    "        reward = rewards[\"reward\"]\n",
    "    else:  # C\n",
    "        reward = generate_random_reward(rewards[\"reward\"], rewards[\"no_reward\"], prob=0.5)\n",
    "    \n",
    "    reversal_abc[\"stimuli\"].append(stim)\n",
    "    reversal_abc[\"rewards\"].append(reward)\n",
    "    reversal_abc[\"masks\"][\"reversal\"].append(1)\n",
    "\n",
    "print(f\"Generated reversal_abc sequence: {len(reversal_abc['stimuli'])} timesteps\")\n",
    "print(f\"  Pre-reversal: {num_expected_occurrences} trials\")\n",
    "print(f\"  Post-reversal: {num_unexpected_occurrences} trials\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Convert to One-Hot Encoded States\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversal AB: 400 states (one-hot encoded)\n",
      "Reversal ABC: 16000 states (one-hot encoded)\n",
      "\n",
      "Reversal ABC phase boundaries:\n",
      "  Pre-reversal: timesteps 0 to 8000\n",
      "  Post-reversal: timesteps 8000 to 16000\n",
      "  Reversal point: [8000]\n"
     ]
    }
   ],
   "source": [
    "# Create one-hot encoders\n",
    "# For reversal_ab: 4 states (A, B, unrewarded, rewarded)\n",
    "# For reversal_abc: 5 states (A, B, C, unrewarded, rewarded)\n",
    "\n",
    "# Reversal AB: state sequence includes stimulus and reward states\n",
    "state_map_ab = {\"A\": 0, \"B\": 1, \"unrewarded\": 2, \"rewarded\": 3}\n",
    "state_sequence_ab = []\n",
    "\n",
    "for stim, reward in zip(reversal_ab[\"stimuli\"], reversal_ab[\"rewards\"]):\n",
    "    # Add stimulus state\n",
    "    if stim == stimuli[\"A\"]:\n",
    "        state_sequence_ab.append(state_map_ab[\"A\"])\n",
    "    else:\n",
    "        state_sequence_ab.append(state_map_ab[\"B\"])\n",
    "    \n",
    "    # Add reward state based on action outcome\n",
    "    # (In actual task, this depends on whether agent licks)\n",
    "    # For now, add reward availability state\n",
    "    if reward == rewards[\"reward\"]:\n",
    "        state_sequence_ab.append(state_map_ab[\"rewarded\"])\n",
    "    else:\n",
    "        state_sequence_ab.append(state_map_ab[\"unrewarded\"])\n",
    "\n",
    "# One-hot encode\n",
    "encoder_ab = OneHotEncoder(sparse_output=False, categories=[range(4)])\n",
    "state_sequence_ohe_ab = encoder_ab.fit_transform(np.array(state_sequence_ab).reshape(-1, 1))\n",
    "\n",
    "# Reversal ABC: similar but with C\n",
    "state_map_abc = {\"A\": 0, \"B\": 1, \"C\": 2, \"unrewarded\": 3, \"rewarded\": 4}\n",
    "state_sequence_abc = []\n",
    "\n",
    "for stim, reward in zip(reversal_abc[\"stimuli\"], reversal_abc[\"rewards\"]):\n",
    "    # Add stimulus state\n",
    "    if stim == stimuli[\"A\"]:\n",
    "        state_sequence_abc.append(state_map_abc[\"A\"])\n",
    "    elif stim == stimuli[\"B\"]:\n",
    "        state_sequence_abc.append(state_map_abc[\"B\"])\n",
    "    else:\n",
    "        state_sequence_abc.append(state_map_abc[\"C\"])\n",
    "    \n",
    "    # Add reward state\n",
    "    if reward == rewards[\"reward\"]:\n",
    "        state_sequence_abc.append(state_map_abc[\"rewarded\"])\n",
    "    else:\n",
    "        state_sequence_abc.append(state_map_abc[\"unrewarded\"])\n",
    "\n",
    "# One-hot encode\n",
    "encoder_abc = OneHotEncoder(sparse_output=False, categories=[range(5)])\n",
    "state_sequence_ohe_abc = encoder_abc.fit_transform(np.array(state_sequence_abc).reshape(-1, 1))\n",
    "\n",
    "print(f\"Reversal AB: {len(state_sequence_ohe_ab)} states (one-hot encoded)\")\n",
    "print(f\"Reversal ABC: {len(state_sequence_ohe_abc)} states (one-hot encoded)\")\n",
    "\n",
    "# Calculate phase boundaries for reversal_abc\n",
    "phase_boundaries_abc = {\n",
    "    \"reversal_points\": [num_expected_occurrences * 2],  # Reversal point at end of pre-reversal phase\n",
    "    \"pre_reversal\": {\n",
    "        \"start\": 0,\n",
    "        \"end\": num_expected_occurrences * 2\n",
    "    },\n",
    "    \"post_reversal\": {\n",
    "        \"start\": num_expected_occurrences * 2,\n",
    "        \"end\": (num_expected_occurrences + num_unexpected_occurrences) * 2\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\nReversal ABC phase boundaries:\")\n",
    "print(f\"  Pre-reversal: timesteps {phase_boundaries_abc['pre_reversal']['start']} to {phase_boundaries_abc['pre_reversal']['end']}\")\n",
    "print(f\"  Post-reversal: timesteps {phase_boundaries_abc['post_reversal']['start']} to {phase_boundaries_abc['post_reversal']['end']}\")\n",
    "print(f\"  Reversal point: {phase_boundaries_abc['reversal_points']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Generate Multi-Reversal ABC Task Sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated reversal_abc_multi sequence: 4000 timesteps\n",
      "  Number of phases: 4\n",
      "  Phase 0 (A rewarded): 1000 trials\n",
      "  Phase 1 (B rewarded): 1000 trials\n",
      "  Phase 2 (A rewarded): 1000 trials\n",
      "  Phase 3 (B rewarded): 1000 trials\n"
     ]
    }
   ],
   "source": [
    "# Parameters for multi-reversal ABC task\n",
    "# Specify number of trials for each reversal phase\n",
    "# A and B reverse: A rewarded -> B rewarded -> A rewarded -> B rewarded -> ...\n",
    "# C always has random 50% reward\n",
    "phase_trials = [2000, 2000, 2000, 2000]  # 4 phases: A rewarded, B rewarded, A rewarded, B rewarded\n",
    "# phase_trials = [1000, 1000, 1000, 1000]  # 4 phases: A rewarded, B rewarded, A rewarded, B rewarded\n",
    "\n",
    "reversal_abc_multi = {\n",
    "    \"stimuli\": [],\n",
    "    \"rewards\": [],\n",
    "    \"masks\": {\"reversal\": []}\n",
    "}\n",
    "\n",
    "# Generate sequence with multiple reversals\n",
    "for phase_idx, num_trials in enumerate(phase_trials):\n",
    "    # Determine which stimulus is rewarded in this phase\n",
    "    # Even phases (0, 2, 4...): A rewarded\n",
    "    # Odd phases (1, 3, 5...): B rewarded\n",
    "    a_rewarded = (phase_idx % 2 == 0)\n",
    "    \n",
    "    for _ in range(num_trials):\n",
    "        stim = np.random.choice([stimuli[\"A\"], stimuli[\"B\"], stimuli[\"C\"]], p=[1/3, 1/3, 1/3])\n",
    "        \n",
    "        if stim == stimuli[\"A\"]:\n",
    "            reward = rewards[\"reward\"] if a_rewarded else rewards[\"no_reward\"]\n",
    "        elif stim == stimuli[\"B\"]:\n",
    "            reward = rewards[\"reward\"] if not a_rewarded else rewards[\"no_reward\"]\n",
    "        else:  # C\n",
    "            reward = generate_random_reward(rewards[\"reward\"], rewards[\"no_reward\"], prob=0.5)\n",
    "        \n",
    "        reversal_abc_multi[\"stimuli\"].append(stim)\n",
    "        reversal_abc_multi[\"rewards\"].append(reward)\n",
    "        reversal_abc_multi[\"masks\"][\"reversal\"].append(phase_idx)\n",
    "\n",
    "print(f\"Generated reversal_abc_multi sequence: {len(reversal_abc_multi['stimuli'])} timesteps\")\n",
    "print(f\"  Number of phases: {len(phase_trials)}\")\n",
    "for i, num_trials in enumerate(phase_trials):\n",
    "    phase_type = \"A rewarded\" if i % 2 == 0 else \"B rewarded\"\n",
    "    print(f\"  Phase {i} ({phase_type}): {num_trials} trials\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Convert Multi-Reversal ABC to One-Hot Encoded States\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversal ABC Multi: 8000 states (one-hot encoded)\n",
      "\n",
      "Phase boundaries:\n",
      "  Phase 0: timesteps 0 to 2000\n",
      "  Phase 1: timesteps 2000 to 4000\n",
      "  Phase 2: timesteps 4000 to 6000\n",
      "  Phase 3: timesteps 6000 to 8000\n",
      "  Reversal points: [2000, 4000, 6000]\n"
     ]
    }
   ],
   "source": [
    "# Reversal ABC Multi: same state mapping as ABC\n",
    "state_map_abc_multi = {\"A\": 0, \"B\": 1, \"C\": 2, \"unrewarded\": 3, \"rewarded\": 4}\n",
    "state_sequence_abc_multi = []\n",
    "\n",
    "for stim, reward in zip(reversal_abc_multi[\"stimuli\"], reversal_abc_multi[\"rewards\"]):\n",
    "    # Add stimulus state\n",
    "    if stim == stimuli[\"A\"]:\n",
    "        state_sequence_abc_multi.append(state_map_abc_multi[\"A\"])\n",
    "    elif stim == stimuli[\"B\"]:\n",
    "        state_sequence_abc_multi.append(state_map_abc_multi[\"B\"])\n",
    "    else:\n",
    "        state_sequence_abc_multi.append(state_map_abc_multi[\"C\"])\n",
    "    \n",
    "    # Add reward state\n",
    "    if reward == rewards[\"reward\"]:\n",
    "        state_sequence_abc_multi.append(state_map_abc_multi[\"rewarded\"])\n",
    "    else:\n",
    "        state_sequence_abc_multi.append(state_map_abc_multi[\"unrewarded\"])\n",
    "\n",
    "# One-hot encode\n",
    "encoder_abc_multi = OneHotEncoder(sparse_output=False, categories=[range(5)])\n",
    "state_sequence_ohe_abc_multi = encoder_abc_multi.fit_transform(np.array(state_sequence_abc_multi).reshape(-1, 1))\n",
    "\n",
    "print(f\"Reversal ABC Multi: {len(state_sequence_ohe_abc_multi)} states (one-hot encoded)\")\n",
    "\n",
    "# Calculate phase boundaries\n",
    "phase_boundaries = {\"reversal_points\": []}\n",
    "cumulative_trials = 0\n",
    "for i, num_trials in enumerate(phase_trials):\n",
    "    if i > 0:  # First phase doesn't have a reversal point before it\n",
    "        phase_boundaries[\"reversal_points\"].append(cumulative_trials * 2)  # Each trial = 2 timesteps\n",
    "    cumulative_trials += num_trials\n",
    "\n",
    "# Add phase boundaries for each phase\n",
    "for i, num_trials in enumerate(phase_trials):\n",
    "    phase_start = sum(phase_trials[:i]) * 2\n",
    "    phase_end = sum(phase_trials[:i+1]) * 2\n",
    "    phase_boundaries[f\"phase_{i}\"] = {\"start\": phase_start, \"end\": phase_end}\n",
    "\n",
    "print(f\"\\nPhase boundaries:\")\n",
    "for i in range(len(phase_trials)):\n",
    "    print(f\"  Phase {i}: timesteps {phase_boundaries[f'phase_{i}']['start']} to {phase_boundaries[f'phase_{i}']['end']}\")\n",
    "print(f\"  Reversal points: {phase_boundaries['reversal_points']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Save to Pickle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved reversal_abc_multi.pkl to /Users/pmccarthy/Documents/StrPFC/new_repo/data\n"
     ]
    }
   ],
   "source": [
    "# Save reversal_abc_multi\n",
    "data_abc_multi = {\n",
    "    \"sequence\": reversal_abc_multi,\n",
    "    \"state_sequence_ohe\": state_sequence_ohe_abc_multi,\n",
    "    \"state_map\": state_map_abc_multi,\n",
    "    \"sequence_ohe\": state_sequence_ohe_abc_multi,  # Alias for compatibility\n",
    "    \"phase_boundaries\": phase_boundaries\n",
    "}\n",
    "\n",
    "with open(data_dir / \"reversal_abc_multi.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data_abc_multi, f)\n",
    "print(f\"Saved reversal_abc_multi.pkl to {data_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved reversal_ab.pkl to /Users/pmccarthy/Documents/StrPFC/new_repo/data\n",
      "Saved reversal_abc.pkl to /Users/pmccarthy/Documents/StrPFC/new_repo/data\n",
      "\n",
      "Task generation complete!\n"
     ]
    }
   ],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "data_dir = Path(\"/Users/pmccarthy/Documents/StrPFC/new_repo/data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save reversal_ab\n",
    "data_ab = {\n",
    "    \"sequence\": reversal_ab,\n",
    "    \"state_sequence_ohe\": state_sequence_ohe_ab,\n",
    "    \"state_map\": state_map_ab,\n",
    "    \"sequence_ohe\": state_sequence_ohe_ab  # Alias for compatibility\n",
    "}\n",
    "\n",
    "with open(data_dir / \"reversal_ab.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data_ab, f)\n",
    "print(f\"Saved reversal_ab.pkl to {data_dir}\")\n",
    "\n",
    "# Save reversal_abc\n",
    "data_abc = {\n",
    "    \"sequence\": reversal_abc,\n",
    "    \"state_sequence_ohe\": state_sequence_ohe_abc,\n",
    "    \"state_map\": state_map_abc,\n",
    "    \"sequence_ohe\": state_sequence_ohe_abc,  # Alias for compatibility\n",
    "    \"phase_boundaries\": phase_boundaries_abc\n",
    "}\n",
    "\n",
    "with open(data_dir / \"reversal_abc.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data_abc, f)\n",
    "print(f\"Saved reversal_abc.pkl to {data_dir}\")\n",
    "\n",
    "print(\"\\nTask generation complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "str_pfc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
